{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import Ipynb_importer\n",
    "import Classic\n",
    "import Subsetselection\n",
    "import k2k_hadamard\n",
    "import timeit\n",
    "import scipy.io as io\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as io\n",
    "\n",
    "#functions to generate distributions\n",
    "def generate_geometric_distribution(k,lbd):\n",
    "    elements = range(0,k)\n",
    "    prob = [(1-lbd)*math.pow(lbd,x)/(1-math.pow(lbd,k)) for x in elements] # geometric dist\n",
    "    return prob\n",
    "\n",
    "def generate_uniform_distribution(k):\n",
    "    raw_distribution = [1] * k\n",
    "    sum_raw = sum(raw_distribution)\n",
    "    prob = [float(y)/float(sum_raw) for y in raw_distribution]\n",
    "    return prob\n",
    "\n",
    "def generate_two_steps_distribution(k):\n",
    "    raw_distribution = [1] * int(k/2) + [3] * int(k/2)\n",
    "    sum_raw = sum(raw_distribution)\n",
    "    prob = [float(y)/float(sum_raw) for y in raw_distribution]\n",
    "    return prob\n",
    "\n",
    "def generate_Zipf_distribution(k,lbd):\n",
    "    raw_distribution = [1/(float(i)**(lbd)) for i in range(1,k+1)]\n",
    "    sum_raw = sum(raw_distribution)\n",
    "    prob = [float(y)/float(sum_raw) for y in raw_distribution]\n",
    "    return prob\n",
    "\n",
    "def generate_Dirichlet_distribution(k,lbd):  \n",
    "    raw_distribution = [0] * k\n",
    "    for i in range(0,k):\n",
    "        raw_distribution[i] = np.random.gamma(1,1)\n",
    "    sum_raw = sum(raw_distribution)\n",
    "    prob = [float(y)/float(sum_raw) for y in raw_distribution]\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(k, eps, rep, points, step_sz, init, dist, encode_acc = 1, mode = 0):\n",
    "    # fix alphabet size and privacy level, get the error plot with respect to sample size\n",
    "    \n",
    "    #Args:\n",
    "    # k : alphabet size,  eps: privacy level, rep: repetition times to compute a point\n",
    "    # points: number of points to compute\n",
    "    # step_sz: distance between two sample sizes\n",
    "    # init: initial sample size = init* step_sz\n",
    "    # dist: underlying data distribution: choose from 'Uniform', 'Two_steps', 'Zipf', 'Dirchlet', 'Geometric'\n",
    "    \n",
    "    # encode_acc : control whether to use fast encoding for hadamard responce\n",
    "    #           recommended and default: 1 use fast encoding when k < 10000\n",
    "    #                                    if memory use is high, disable this\n",
    "    \n",
    "    # mode: control encoding method for rappor and subset selection\n",
    "    #       0 for standard, which is fast but memory intensive\n",
    "    #       1 for light, which is relatively slow but not memory intensive\n",
    "    #       2 for compress, where we compress the output of rappor and subsetselection into locations of ones.\n",
    "    #       recommended and default: 0 when k <= 5000 n <= 1000000\n",
    "    #                               if memory use is high, use light mode\n",
    "    #       you can also create other modes by modifying the code\n",
    "    print('Alphabet size:', k)\n",
    "    print('Privacy level:', eps)\n",
    "    \n",
    "    indicies = [(init-1+i)*step_sz for i in range(1,points+1) ] # all the indicies\n",
    "    \n",
    "    a = Subsetselection.Subsetselection(k,eps) #class for subset selection algorithm\n",
    "    \n",
    "    if encode_acc == 1:\n",
    "        b = k2k_hadamard.Hadamard_Rand_2_modified(k,eps,1) #initialize hadamard response\n",
    "    else:\n",
    "        b = k2k_hadamard.Hadamard_Rand_2_modified(k,eps,0) #initialize hadamard response\n",
    "    \n",
    "    prob1 = generate_uniform_distribution(k)\n",
    "    prob2 = generate_two_steps_distribution(k)\n",
    "    prob3 = generate_Zipf_distribution(k,1.0)\n",
    "    prob4 = generate_Dirichlet_distribution(k,1.0)\n",
    "    prob5 = generate_geometric_distribution(k,0.8)\n",
    "\n",
    "    prob_list = {\n",
    "        'Uniform' : prob1,\n",
    "        'Two_steps' : prob2,\n",
    "        'Zipf' : prob3,\n",
    "        'Dirchlet' : prob4,\n",
    "        'Geometric' : prob5, \n",
    "        }\n",
    "    #underlying distribution\n",
    "    prob = prob_list[dist]\n",
    "    \n",
    "    # to store l1 errors for each method\n",
    "    l1_1 = [0]*points\n",
    "    l1_2 = [0]*points\n",
    "    l1_3 = [0]*points\n",
    "    l1_4 = [0]*points\n",
    "    \n",
    "    # to store l2 errors for each method\n",
    "    l2_1 = [0]*points\n",
    "    l2_2 = [0]*points\n",
    "    l2_3 = [0]*points\n",
    "    l2_4 = [0]*points\n",
    "\n",
    "    # to store decodign time for each method\n",
    "    t1_1 = [0]*points\n",
    "    t1_2 = [0]*points\n",
    "    t1_3 = [0]*points\n",
    "    t1_4 = [0]*points\n",
    "\n",
    "    for r in range(init, points + init):\n",
    "        print('Iteration:', r)\n",
    "        n = r*step_sz\n",
    "        count1 = 0\n",
    "        count2 = 0\n",
    "        count3 = 0\n",
    "        count4 = 0\n",
    "        count2_1 = 0\n",
    "        count2_2 = 0\n",
    "        count2_3 = 0\n",
    "        count2_4 = 0\n",
    "        t1 = 0\n",
    "        t2 = 0\n",
    "        t3 = 0\n",
    "        t4 = 0\n",
    "        for t in range(0,rep):\n",
    "            #print(t)\n",
    "            elements = range(0,k)\n",
    "            in_list = np.random.choice(elements, n, p=prob) #input symbols\n",
    "            \n",
    "            #subset selection\n",
    "            if mode == 0: # standard mode\n",
    "                outp_1 = a.encode_string_fast(in_list) \n",
    "                start_time = timeit.default_timer()\n",
    "                prob_est_1 = a.decode_string(outp_1,n) # estimate the original underlying distribution\n",
    "                t1 = t1 + timeit.default_timer() - start_time\n",
    "            if mode == 1: # light mode\n",
    "                counts,time = a.encode_string_light(in_list) #subset selection\n",
    "                start_time = timeit.default_timer()\n",
    "                prob_est_1 = a.decode_counts(counts, n) # estimate the original underlying distribution\n",
    "                t1 = t1 + time + timeit.default_timer() - start_time\n",
    "            if mode == 2: # compress mode\n",
    "                out_list = a.encode_string_compress(in_list) #subset selection\n",
    "                start_time = timeit.default_timer()\n",
    "                counts, temp = np.histogram(out_list,range(k+1))\n",
    "                prob_est_1 = a.decode_counts(counts, n) # estimate the original underlying distribution\n",
    "                t1 = t1 + timeit.default_timer() - start_time\n",
    "            count1 = count1 + np.linalg.norm([a_i - b_i for a_i, b_i in zip(prob, prob_est_1)], ord=1) \n",
    "            count2_1 = count2_1 + np.linalg.norm([a_i - b_i for a_i, b_i in zip(prob, prob_est_1)], ord=2)**2\n",
    "\n",
    "            # k- RR\n",
    "            sample = Classic.randomized_response_encoder(in_list, eps, k) \n",
    "            start_time = timeit.default_timer()\n",
    "            (outp_2, temp) = np.histogram(sample,range(k+1))\n",
    "            prob_est_2 = Classic.rr_decoder(outp_2,eps,n) # estimate the original underlying distribution\n",
    "            t2 = t2 + timeit.default_timer() - start_time\n",
    "            count2 = count2 + np.linalg.norm([a_i - b_i for a_i, b_i in zip(prob, prob_est_2)], ord=1) \n",
    "            count2_2 = count2_2 + np.linalg.norm([a_i - b_i for a_i, b_i in zip(prob, prob_est_2)], ord=2)**2\n",
    "            \n",
    "            #k-RAPPOR\n",
    "            if mode == 0: \n",
    "                sample = Classic.rappor_encoder(in_list, eps, k) \n",
    "                start_time = timeit.default_timer()\n",
    "                outp_3 = np.sum(sample, axis=0)\n",
    "                prob_est_3 = Classic.rappor_decoder(outp_3,eps,n) # estimate the original underlying distribution\n",
    "                t3 = t3 + timeit.default_timer() - start_time\n",
    "            if mode == 1:\n",
    "                counts, time = Classic.rappor_encoder_light(in_list, eps, k)\n",
    "                start_time = timeit.default_timer()\n",
    "                prob_est_3 = Classic.rappor_decoder(counts,eps,n) # estimate the original underlying distribution\n",
    "                t3 = t3 + time + timeit.default_timer() - start_time\n",
    "            if mode == 2:\n",
    "                out_list = Classic.rappor_encoder_compress(in_list, eps, k)\n",
    "                start_time = timeit.default_timer()\n",
    "                counts,temp = np.histogram(out_list,range(k+1))\n",
    "                prob_est_3 = Classic.rappor_decoder(counts,eps,n) # estimate the original underlying distribution\n",
    "                t3 = t3 + timeit.default_timer() - start_time\n",
    "            count3 = count3 + np.linalg.norm([a_i - b_i for a_i, b_i in zip(prob, prob_est_3)], ord=1) \n",
    "            count2_3 = count2_3 + np.linalg.norm([a_i - b_i for a_i, b_i in zip(prob, prob_est_3)], ord=2)**2\n",
    "\n",
    "            #k-HR\n",
    "            outp_4 = b.encode_string(in_list) \n",
    "            start_time = timeit.default_timer()\n",
    "            prob_est_4 = b.decode_string(outp_4) # estimate the original underlying distribution\n",
    "            t4 = t4 + timeit.default_timer() - start_time\n",
    "            count4 = count4 + np.linalg.norm([a_i - b_i for a_i, b_i in zip(prob, prob_est_4)], ord=1) \n",
    "            count2_4 = count2_4 + np.linalg.norm([a_i - b_i for a_i, b_i in zip(prob, prob_est_4)], ord=2)**2\n",
    "\n",
    "        l1_1[r-1] = count1/float(rep)\n",
    "        l1_2[r-1] = count2/float(rep)\n",
    "        l1_3[r-1] = count3/float(rep)\n",
    "        l1_4[r-1] = count4/float(rep)\n",
    "        \n",
    "        l2_1[r-1] = count2_1/float(rep)\n",
    "        l2_2[r-1] = count2_2/float(rep)\n",
    "        l2_3[r-1] = count2_3/float(rep)\n",
    "        l2_4[r-1] = count2_4/float(rep)\n",
    "        \n",
    "        t1_1[r-1] = t1/float(rep)\n",
    "        t1_2[r-1] = t2/float(rep)\n",
    "        t1_3[r-1] = t3/float(rep)\n",
    "        t1_4[r-1] = t4/float(rep)\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.plot(indicies,l1_1, label = 'subset')\n",
    "    plt.plot(indicies,l1_2, label = 'rr')\n",
    "    plt.plot(indicies,l1_3, label = 'rappor')\n",
    "    plt.plot(indicies,l1_4, label = 'hr')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(indicies,l2_1, label = 'subset')\n",
    "    plt.plot(indicies,l2_2, label = 'rr')\n",
    "    plt.plot(indicies,l2_3, label = 'rappor')\n",
    "    plt.plot(indicies,l2_4, label = 'hr')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(indicies,t1_1, label = 'subset')\n",
    "    plt.plot(indicies,t1_2, label = 'rr')\n",
    "    plt.plot(indicies,t1_3, label = 'rappor')\n",
    "    plt.plot(indicies,t1_4, label = 'hr')\n",
    "    plt.legend()\n",
    "    time = datetime.datetime.now().strftime(\"%m_%d_%H_%M\")\n",
    "\n",
    "    #save all the data into a mat file with time stamp\n",
    "    data = {\n",
    "        'time' : time,\n",
    "        'absz' : k,\n",
    "        'privacy' : eps,\n",
    "        'repetition' : rep,\n",
    "        'indices' : indicies, # indices of each point (number of samples)\n",
    "        'subset_error': l1_1, #l1 error for each point\n",
    "        'rr_error': l1_2,\n",
    "        'rappor_error': l1_3,\n",
    "        'hr_error': l1_4,\n",
    "        'subset_error_l2': l2_1, #l2 error for each point\n",
    "        'rr_error_l2': l2_2,\n",
    "        'rappor_error_l2': l2_3,\n",
    "        'hr_error_l2': l2_4,\n",
    "        'subset_time': t1_1, #decoding time for each point\n",
    "        'rr_time': t1_2,\n",
    "        'rappor_time': t1_3,\n",
    "        'hr_time': t1_4,\n",
    "        'prob': prob,\n",
    "        'dist': dist\n",
    "    }\n",
    "    para = 'k_{}_eps_{}_'.format(k,eps)\n",
    "    filename = 'Data/data_' + dist + '_' + para + time\n",
    "    io.savemat(filename,data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Testing script for comparison\n",
    "k = 100 #absz\n",
    "eps = 2 # privacy_para\n",
    "rep = 10 #repetition time for each point\n",
    "points = 10 # total number of points\n",
    "step_sz = 5000 # step size between two points\n",
    "init = 1 #initial step\n",
    "\n",
    "for dist in ['Geometric']:\n",
    "    print(dist)\n",
    "    for eps in [2]:\n",
    "        print(datetime.datetime.now())\n",
    "        data = test(k,eps,rep,points,step_sz,init,dist,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100 #absz\n",
    "n = 100000\n",
    "eps = 1 # privacy_para\n",
    "\n",
    "# prob = generate_geometric_distribution(k,0.8)\n",
    "# prob = generate_uniform_distribution(k)\n",
    "prob = generate_two_steps_distribution(k)\n",
    "# prob = generate_Zipf_distribution(k,1.0)\n",
    "# prob = generate_Dirchlet_distribution(k,1.0)\n",
    "\n",
    "elements = range(0,k)\n",
    "in_list = np.random.choice(elements, n, p=prob) #input symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetselection\n",
    "a = Subsetselection.Subsetselection(k,eps) \n",
    "#print (a.partsz)\n",
    "#print (elements.type)\n",
    "# print(type(in_list[9]))\n",
    "outp = a.encode_string(in_list)\n",
    "prob_est = a.decode_string(outp,n) # estimate the original underlying distribution\n",
    "plt.plot(elements,prob)\n",
    "plt.plot(elements,prob_est)\n",
    "#plt.plot(prob_est)\n",
    "print (\"l1 distance: \", str(np.linalg.norm([a_i - b_i for a_i, b_i in zip(prob, prob_est)], ord=1)))\n",
    "print (\"prob_sum: \", str(sum(prob_est)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-rr\n",
    "sample = Classic.randomized_response_encoder(in_list, eps, k)\n",
    "(outp, temp) = np.histogram(sample,range(k+1))\n",
    "#print outp\n",
    "prob_est = Classic.rr_decoder(outp,eps,n) # estimate the original underlying distribution\n",
    "plt.plot(elements,prob)\n",
    "plt.plot(elements,prob_est)\n",
    "#plt.plot(prob_est)\n",
    "print (\"l1 distance: \", str(np.linalg.norm([a_i - b_i for a_i, b_i in zip(prob, prob_est)], ord=1)))\n",
    "print (\"prob_sum: \", str(sum(prob_est)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-rappor\n",
    "sample = Classic.rappor_encoder(in_list, eps, k)\n",
    "outp = np.sum(sample, axis=0)\n",
    "prob_est = Classic.rappor_decoder(outp,eps,n) # estimate the original underlying distribution\n",
    "plt.plot(elements,prob)\n",
    "plt.plot(elements,prob_est)\n",
    "#plt.plot(prob_est)\n",
    "print (\"l1 distance: \", str(np.linalg.norm([a_i - b_i for a_i, b_i in zip(prob, prob_est)], ord=1)))\n",
    "print (\"prob_sum: \", str(sum(prob_est)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = k2k_hadamard.Hadamard_Rand_2_modified(k,eps) \n",
    "#print (a.partsz)\n",
    "#print (elements.type)\n",
    "# print(type(in_list[9]))\n",
    "outp = b.encode_string(in_list)\n",
    "#print outp\n",
    "prob_est = b.decode_string(outp) # estimate the original underlying distribution\n",
    "plt.plot(elements,prob)\n",
    "plt.plot(elements,prob_est)\n",
    "#plt.plot(prob_est)\n",
    "print (\"l1 distance: \", str(np.linalg.norm([a_i - b_i for a_i, b_i in zip(prob, prob_est)], ord=1)))\n",
    "print (\"prob_sum: \", str(sum(prob_est)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
